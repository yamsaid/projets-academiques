---
output: 
  pdf_document:
    latex_engine: xelatex  
    number_sections: true
    toc: true
    toc_depth: 2
    includes:
      in_header: preamble.tex
      before_body: titlepage.tex
fontsize: 11pt
geometry: margin=2.5cm
lang: fr
---





## Introduction

Le d√©veloppement urbain rapide que connaissent de nombreuses villes africaines s‚Äôaccompagne d‚Äôune pression croissante sur les ressources fonci√®res. √Ä Ouagadougou, la capitale du Burkina Faso, cette dynamique se traduit par une intensification des transactions fonci√®res et une augmentation progressive du co√ªt des parcelles. Face √† cette √©volution, il devient crucial pour les acteurs publics et priv√©s, notamment les am√©nageurs et les autorit√©s locales, de disposer d‚Äôoutils de mesure fiables permettant de suivre l‚Äô√©volution des prix du foncier.

L'√©valuation de l'√©volution des prix des parcelles immobili√®res constitue un enjeu majeur pour les acteurs √©conomiques, les d√©cideurs politiques et les investisseurs, permettant de mieux comprendre les dynamiques du march√© immobilier et d'orienter les strat√©gies d'investissement ou de r√©gulation. Dans ce contexte, la p√©riode s'√©tendant de 2018 √† 2024 offre un cadre pertinent pour analyser les fluctuations des prix, marqu√©es par des √©v√©nements √©conomiques et sociaux significatifs.

Cependant, la construction d‚Äôun tel indicateur pose plusieurs d√©fis. Une simple comparaison des prix moyens d‚Äôune ann√©e √† l‚Äôautre ne permet pas de distinguer les variations r√©elles des prix de celles li√©es √† des changements dans la nature des parcelles vendues (localisation, superficie, usage, statut administratif, etc.). Autrement dit, il est essentiel de neutraliser l‚Äôeffet qualit√© pour isoler la variation purement temporelle des prix.

C‚Äôest dans ce cadre que s‚Äôinscrit la m√©thode h√©donique, utilis√©e dans de nombreux pays pour la construction d‚Äôindices immobiliers ajust√©s. Cette m√©thode repose sur l‚Äôid√©e que le prix d‚Äôun bien est fonction de ses caract√©ristiques observables. Elle permet ainsi de mod√©liser la contribution individuelle de chaque attribut (par exemple : superficie, quartier, usage pr√©vu) √† la formation du prix, et de construire un indice de prix corrig√© des effets de composition.




```{r , message=FALSE, warning=FALSE, echo=FALSE}
## Chargement des packages
library(readr) # Pour importer la base
library(tidyverse)  # Pour la manipulation des donn√©es
library(lubridate)  # Pour les dates
library(lmtest)     # Pour les tests √©conom√©triques
library(car)        # Pour le VIF
library(VIM)        #Visualisation des valeurs manquantes
library(psych)      # Statistique descriptives
library(corrplot)   # pour la matrice de correlation
library(dplyr)       # pour les traitements
library(car)        # pour les tests
library(xgboost)
library(Matrix)
library(caret)
library(e1071)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(rcompanion)
library(tibble)
library(knitr)
library(kableExtra)
library(scales)
library(ggplot2)
library(mgcv)



```



```{r, warning = FALSE, message = FALSE, echo = FALSE}
## Importation des donn√©es
sonatur <- read_delim("Sonatur_csvf.csv", delim = ";", escape_double = FALSE, 
                       trim_ws = TRUE)

col = c( "Numero","Ville" , "Site",
         "Usage", "Superficie", "Cout_m2",
         "COUT", "Taxe_Jouissance", "Type_option",
         "Date_vente", "Date_fin_contrat","attestation_etablie",
         "plan_etablie", "Presence_ONEA","Presence_SONABEL" 
)

names(sonatur)<- col

#Convertir en factor
sonatur <- sonatur %>%
  mutate(across(where(is.character), as.factor))

```

## Pr√©sentation des donn√©es

###  Sources de donn√©es 

Les donn√©es utilis√©es dans cette √©tude proviennent de la Soci√©t√© Nationale d‚ÄôAm√©nagement des Terrains Urbains (SONATUR). Elles portent sur l‚Äôensemble des parcelles vendues √† Ouagadougou entre 2018 et 2024, issues de diff√©rents sites d‚Äôam√©nagement. Chaque enregistrement correspond √† une parcelle individuelle pour laquelle diverses caract√©ristiques ont √©t√© renseign√©es.

La base de donn√©es comprend 1811 d‚Äôobservations et 15 variables et couvre aussi bien des zones p√©riph√©riques que des quartiers plus centraux. Elle constitue une source pr√©cieuse pour analyser l‚Äô√©volution des prix fonciers et mod√©liser la valeur des terrains √† partir de leurs attributs.


###  Analyse descriptive pr√©liminaire

Avant de proc√©der √† la construction des variables synth√©tiques et √† la mod√©lisation, une analyse descriptive des donn√©es a √©t√© r√©alis√©e pour explorer les caract√©ristiques des parcelles et identifier les relations potentielles entre les variables.

#### - Variables quantitatives

Le tableau ci-dessous pr√©sente les indicateurs statistiques cl√©s moyenne, m√©diane, √©cart-type, minimum, maximum et asym√©trie pour variables quantitatives : le cout par m2 (Cout_m2),le co√ªt total de parcelles (COUT), la superficie (superficie) et le taxe de jouissance (Taxe_Jouissance).



```{r, echo = FALSE, message = FALSE, warning = FALSE}

# Variables s√©lectionn√©es
quanti_vars <- c("Cout_m2", "COUT", "Superficie", "Taxe_Jouissance")

data_check <- sonatur %>%
  select(all_of(quanti_vars))

# Fonction de r√©sum√© pour une variable
resumer_variable <- function(v) {
  c(Moyenne = mean(v, na.rm = TRUE),
    Mediane = median(v, na.rm = TRUE),
    Ecart_type = sd(v, na.rm = TRUE),
    Minimum = min(v, na.rm = TRUE),
    Maximum = max(v, na.rm = TRUE),
    Asymetrie = skewness(v, na.rm = TRUE))
}

# Appliquer √† chaque variable
summary_quanti <- data.frame(t(sapply(data_check, resumer_variable)))
summary_quanti <- tibble::rownames_to_column(summary_quanti, var = "Variable")

# Affichage du tableau
kable(summary_quanti, digits = 2, caption = "R√©sum√© statistique des variables quantitatives") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, font_size = 10)

```

Le r√©sum√© statistique des variables quantitatives met en √©vidence des disparit√©s notables entre les indicateurs observ√©s. Le co√ªt par m2 (Cout_m2), le co√ªt total (COUT) et les taxes de jouissance (Taxe_Jouissance) pr√©sente une moyenne √©lev√©e respectivement 27349.66 FCFA, 16068350.47 FCFA, 514.77 FCFA, mais une forte asym√©trie positive respectivement 1.68, 11.13, 2.89 indiquant la pr√©sence de valeurs extr√™mes vers le haut, ce que confirme l‚Äô√©cart important entre le minimum respectivement 0, 0, 0 et le maximum respectivement 190000 FCFA, 722376000 FCFA,3000 FCFA. Quant √† la superficie, on remarque √©galement une forte as√©metrie (9,84) temoignant un √©talement vers la droite.

On note une incoh√©rence dans les donn√©es via ces variables: des parcelles qui co√ªtent 0 FCFA.

```{r, echo=FALSE, warning=FALSE, results='hide'}

plots_hist <- lapply(quanti_vars, function(var) {
  ggplot(sonatur, aes_string(x = var)) +
    geom_histogram(bins = 30, fill = "#69b3a2", color = "white") +
    labs(title = paste("Histogramme de", var), x = var, y = "Effectif") +
    theme_minimal()
})

# Afficher les 4 histogrammes ensemble
#do.call(grid.arrange, c(plots_hist, ncol = 2))

```


```{r, echo=FALSE, warning=FALSE, results='hide'}
plots_box <- lapply(quanti_vars, function(var) {
  ggplot(sonatur, aes_string(y = var)) +
    geom_boxplot(fill = "#ffa07a", color = "black") +
    labs(title = paste("Boxplot de", var), y = var) +
    theme_minimal()
})

# Afficher les 4 boxplots ensemble
#do.call(grid.arrange, c(plots_box, ncol = 2))

```

#### - Variables qualitatives

```{r, echo=FALSE, warning=FALSE}


#  Variables qualitatives √† r√©sumer
qual_vars <- c("Ville", "Site", "Usage", "Type_option",
               "attestation_etablie", "plan_etablie", 
               "Presence_ONEA", "Presence_SONABEL")

# Resum√© personnalis√©
resumer_categorielle <- function(v) {
  v <- as.character(v)
  tab <- table(v)
  prop <- prop.table(tab)
  mode <- names(tab)[which.max(tab)]
  mode_freq <- max(tab)
  mode_pct <- round(100 * max(prop), 1)
  na_count <- sum(is.na(v))
  n_modalites <- length(tab)
  
  c(Nb_modalites = n_modalites,
    Modalite_dominante = mode,
    Effectif = mode_freq,
    Pourcentage = mode_pct,
    Valeurs_manquantes = na_count)
}

# Appliquer la fonction √† chaque variable
summary_quali <- t(sapply(sonatur[qual_vars], resumer_categorielle)) %>% 
  as.data.frame() %>%
  tibble::rownames_to_column(var = "Variable")

# Affichage avec kable
kable(summary_quali, caption = "R√©sum√© descriptif des variables qualitatives") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, font_size = 11)


```

L‚Äôexploration descriptive des variables qualitatives met en √©vidence plusieurs caract√©ristiques structurelles de l‚Äô√©chantillon √©tudi√©.

Tout d‚Äôabord, la variable Ville pr√©sente une seule modalit√©, √† savoir Ouagadougou, qui regroupe l‚Äôint√©gralit√© des observations. Cette homog√©n√©it√© territoriale est coh√©rente avec le p√©rim√®tre de l‚Äô√©tude, centr√© exclusivement sur la capitale burkinab√®.

La variable Site, quant √† elle, comprend six modalit√©s, refl√©tant les diff√©rents sites d‚Äôam√©nagement couverts par la SONATUR. Toutefois, on observe une forte concentration des ventes sur un seul site, SILMIOUGOU, qui repr√©sente √† lui seul 64,6% de l‚Äô√©chantillon. Cette surrepr√©sentation peut r√©sulter d‚Äôun programme d‚Äôam√©nagement massif ou d‚Äôune politique de commercialisation prioritaire men√©e dans cette zone.

S‚Äôagissant de la variable Usage, dix types d‚Äôusages ont √©t√© identifi√©s, mais la cat√©gorie "Habitation" domine tr√®s largement, repr√©sentant 64,5% des parcelles. Cette configuration met en √©vidence l‚Äôorientation r√©sidentielle majoritaire des projets fonciers, traduisant la forte demande en logements dans le contexte urbain ouagalais.

La variable Type_option regroupe trois modalit√©s relatives aux modalit√©s de paiement ou d‚Äôattribution. La modalit√© "ACOMPTE 30%" est de loin la plus fr√©quente (75,4%), ce qui semble indiquer une strat√©gie commerciale pr√©dominante privil√©giant les paiements √©chelonn√©s avec acompte initial.

Les variables administratives attestation_etablie et plan_etablie pr√©sentent un profil similaire : la modalit√© "NON D√âFINI" est la plus fr√©quente, repr√©sentant respectivement 72,1% et 75,0% des cas. Cette pr√©dominance sugg√®re soit un d√©faut de saisie d‚Äôinformation dans les bases de la SONATUR, soit une absence g√©n√©ralis√©e de formalisation documentaire au moment de la vente.

Enfin, les variables relatives √† la pr√©sence des r√©seaux d‚Äôeau potable (ONEA) et d‚Äô√©lectricit√© (SONABEL) indiquent que 100% des parcelles disposent de ces services. Ce constat t√©moigne d‚Äôun certain niveau d‚Äôam√©nagement des terrains commercialis√©s, et sugg√®re que l‚Äôacc√®s aux infrastructures de base est garanti pour l‚Äôensemble de l‚Äô√©chantillon

### Traitement de la base

```{r, echo=FALSE, warning=FALSE,results='hide'}


sonatur$Date_fin_contrat <- as.Date(sonatur$Date_fin_contrat,format = "%d/%m/%Y")
sonatur$Date_vente <- as.Date(sonatur$Date_vente,format = "%d/%m/%Y")

# Convertir Date vente en format date et extraire l'ann√©e
sonatur$Annee <- year(sonatur$Date_vente)
sonatur$Annee <- as.factor(sonatur$Annee)
```

Nous avons cr√©√© la variable Annee (les ann√©es ) √† partir de la date de vente. Nous avons appliqu√© la fonction logarithme sur les variables quantitatives (Cout_m2, COUT, Superficie et Taxe_Jouissance) pour facilit√© l'interpretation des resultats.

#### - Gestion des valeurs observations incoh√©rentes et les valeurs manquantes

- La base a une seule valeur manquante ce qui nous permet de la supprimer sans compromettre nos analyses.
```{r, echo=FALSE, warning=FALSE, results='hide'}

sum(is.na(sonatur))
sonatur <- na.omit(sonatur)
```
- Les observations incoh√©rentes
Dans notre base il existe des contrats comptant 30% (l'acqu√©reur a r√©gl√© 30% du prix total de la parcelle imm√©diatement, comme acompte.) avec une date de fin de contrat √©gale √† la date de debut.Ce qui est incoherent. Nous remarquons √©galement que les parcelles dont le co√ªt est de 0 FCFA sont li√©es √† ces observations. Nous allons donc les supprimer.

```{r, , echo=FALSE, warning=FALSE, results='hide'}
# correction des incoherrences 
sonatur <- sonatur[ - which((sonatur$Date_vente==sonatur$Date_fin_contrat) & sonatur$Type_option != "COMPTANT"), ]

```



### Recodage des variables

Les variables Site et Usage contiennent des modalit√©s tr√®s peu represent√©es. 

```{r, echo=FALSE, warning=FALSE}

# üîπ Fonction pour g√©n√©rer un tableau de fr√©quences
table_frequence <- function(data, variable) {
  data %>%
    count(!!sym(variable)) %>%
    mutate(Pourcentage = round(100 * n / sum(n), 1)) %>%
    rename(Modalit√© = !!sym(variable), Effectif = n)
}

# üîπ Tableau pour Site
site_freq <- table_frequence(sonatur, "Site")

# üîπ Tableau pour Usage
usage_freq <- table_frequence(sonatur, "Usage")

# üîπ Affichage avec kable
kable(site_freq, caption = "Effectif par modalit√© pour la variable 'Site'") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, font_size = 11)

kable(usage_freq, caption = "Effectif par modalit√© pour la variable 'Usage'") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, font_size = 11)


```

Pour une stabilit√© dans la mod√©lisation nous avons regrouper les modalit√©s √† faible effectif en utilisant l'Analyse en Composantes Multiples (ACM) pour identifier les groupes homog√®nes.


```{r, echo=FALSE, warning=FALSE,results='hide'}
# Sous-ensemble des donn√©es

acm_data <- sonatur %>%
  select(Site) %>%
  filter(!is.na(Site))  # important pour ACM

res_acm1 <- MCA(acm_data, graph = FALSE)

# Graphique des modalit√©s (individus = parcelles non montr√©s ici)


acm_data <- sonatur %>%
  select(Usage) %>%
  filter(!is.na(Usage))  # important pour ACM

res_acm <- MCA(acm_data, graph = FALSE)


# Cr√©e les deux objets graphiques
plot1 <- fviz_mca_var(res_acm1, repel = TRUE, ggtheme = theme_minimal(),
                      title = "Projection des modalit√©s (ACM 1)")

plot2 <- fviz_mca_var(res_acm, repel = TRUE, ggtheme = theme_minimal(),
                      title = "Projection des modalit√©s (ACM 2)")

# Affichage c√¥te √† c√¥te

 
```


Nous avons identifier pour la variable Usage, trois classes : "COMMERCE ANGLE 2 VOIES", "COMMERCE ANGLE 1 BITUME", "COMMERCE" classe 1, "STATION SERVICE", "HABITATION ANGLE", "COMMUNAUTAIRE" classe 2 et "HABITATION", "COMMERCE ORDINAIRE ANGLE", "COMMERCE  A L'ANGLE" classe 3. La nouvelle variable est nomm√©e Usage_rec.

Quant √† la variable Site, on a fait un regroupement des modalit√©s "CISSIN 2020 - SITE G", "OUAGA 2000 - SITE A", "SECTEUR 16 OUAGA" en "SITE GROUPE"

```{r, echo=FALSE, warning=FALSE,results='hide'}
## Recodage de donnees$Site en donnees$Site_rec
sonatur$Site_rec <- sonatur$Site |>
  fct_recode(
    "SITE GROUPE" = "CISSIN 2020 - SITE G",
    "SITE GROUPE" = "OUAGA 2000 - SITE A",
    "SITE GROUPE" = "SECTEUR 16 OUAGA"
  )## Recodage de donnees$Usage en donnees$Usage_rec
sonatur$Usage_rec <- sonatur$Usage |>
  fct_recode(
    "1" = "COMMERCE",
    "3" = "COMMERCE  A L'ANGLE",
    "2" = "COMMERCE ANGLE",
    "1" = "COMMERCE ANGLE 1 BITUME",
    "1" = "COMMERCE ANGLE 2 VOIES",
    "3" = "COMMERCE ORDINAIRE ANGLE",
    "2" = "COMMUNAUTAIRE",
    "3" = "HABITATION",
    "2" = "HABITATION ANGLE",
    "2" = "STATION SERVICE"
  )

```

### Transformation des variables (log)

Dans cette √©tude, la transformation logarithmique a √©t√© appliqu√©e aux variables quantitatives. Cette d√©marche r√©pond √† plusieurs objectifs :
- Stabiliser la variance et limiter les effets d‚Äôh√©t√©rosc√©dasticit√© dans les r√©sidus du mod√®le.
- R√©duire l‚Äôasym√©trie des distributions (souvent tr√®s √©tal√©es √† droite), afin de rapprocher les variables de la normalit√©.
- Mieux interpr√©ter √©conomiquement les coefficients, notamment en termes d‚Äô√©lasticit√© ou de variation en pourcentage.
- Diminuer l‚Äôimpact des valeurs extr√™mes, qui pourraient fausser les r√©sultats du mod√®le lin√©aire.
Ainsi, la transformation logarithmique contribue √† am√©liorer la qualit√©, la robustesse et l‚Äôinterpr√©tabilit√© du mod√®le √©conom√©trique.

```{r, echo=FALSE, warning=FALSE, results='hide'}
# log des variables quanti
sonatur$Cout_m2 <- log(sonatur$Cout_m2)
sonatur$Superficie <- log(sonatur$Superficie)
sonatur$Taxe_Jouissance <- log(sonatur$Taxe_Jouissance)
sonatur$COUT <- log(sonatur$COUT)

```

### Choix des variables

```{r, , echo=FALSE, warning=FALSE}

#  Variables qualitatives √† r√©sumer
qual_vars <- c("Ville", "Site_rec", "Usage_rec", "Type_option",
               "attestation_etablie", "plan_etablie", 
               "Presence_ONEA", "Presence_SONABEL")

# Resum√© personnalis√©
resumer_categorielle <- function(v) {
  v <- as.character(v)
  tab <- table(v)
  prop <- prop.table(tab)
  mode <- names(tab)[which.max(tab)]
  mode_freq <- max(tab)
  mode_pct <- round(100 * max(prop), 1)
  na_count <- sum(is.na(v))
  n_modalites <- length(tab)
  
  c(Nb_modalites = n_modalites,
    Modalite_dominante = mode,
    Effectif = mode_freq,
    Pourcentage = mode_pct,
    Valeurs_manquantes = na_count)
}

# Appliquer la fonction √† chaque variable
summary_quali <- t(sapply(sonatur[qual_vars], resumer_categorielle)) %>% 
  as.data.frame() %>%
  tibble::rownames_to_column(var = "Variable")

# Affichage avec kable
kable(summary_quali, caption = "R√©sum√© descriptif des variables qualitatives") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE, font_size = 11)


```

En observant le tableau ci-dessus, nous constatons que certaines variables telles que la ville (Ville), la presence de la SONABEL (Presence_SONABEL) et la presence d'ONEA (Presence_ONEA) sont des constantes ( une seule modalit√©) elles n'apportent donc pas d'information; ce qui nous permet de les ignorer simplement.

La variable COUT (le cout total de la parcelle) est √©galement ignor√©e dans cette √©tude. En effet COUT = Cout_m2 * Superficie, elle est donc une correl√©e avec la superficie.

Quant aux variables "attestation_etablie", "plan_etablie", "Type_option" et "Usage_rec", elles sont peu diversifi√©es (les modes representent respectivements 66.1% , 69.6% , 70.2% et 72.8% du nombre total d'observations des variables respectives). 
Neamoins la variable Usage_rec traduit la destination l√©gale ou pr√©vue du terrain, ce qui peut influencer directement sur son attractivit√© √©conomique. Les variables administratives telles que plan_etablie et attestation_etablie rendent compte du niveau de formalisation et de la s√©curit√© juridique des parcelles, deux dimensions qui influencent les comportements d‚Äôachat.
La variable "Type_option" renseigne sur le mode de paiement appliqu√© lors de la transaction (paiement comptant, acompte 30%, acompte 50%).Ce mode contractuel a un effet direct sur la formation du prix, dans la mesure o√π le paiement diff√©r√© peut inclure une prime de financement ou refl√©ter un co√ªt d‚Äôopportunit√©. √Ä l‚Äôinverse, un paiement comptant peut entra√Æner une d√©cote.

Le variable Site_rec avec 4 modalit√©s, est un peu diversifi√© au regard du mode (56.9% des observations) ce qui est prometteuse en mati√®re d'information. Par ailleurs La variable Site_rec capture les effets spatiaux li√©s √† la localisation du terrain, un facteur largement reconnu comme d√©terminant dans la valorisation fonci√®re.

La variable Annee est la variable temporelle pour la construction de l'indice.

La variable d√©pendante retenue est le co√ªt par m√®tre carr√© (Cout_m2). Ce choix se justifie d‚Äôune part par la n√©cessit√© de comparer les parcelles sur une base √©quivalente, ind√©pendamment de leur superficie, et d‚Äôautre part par le fait que cette variable constitue un indicateur synth√©tique du prix unitaire du foncier. Elle permet ainsi de quantifier la valeur implicite des caract√©ristiques intrins√®ques et extrins√®ques du terrain, tout en facilitant la construction d‚Äôun indice de prix homog√®ne au cours du temps.

Nous allons valider le choix de ces variables par le test de multicolin√©arit√© (VIF).

```{r, echo=FALSE, warning=FALSE}

vars_exp = c("Superficie","Type_option", "Annee", "Site_rec", "Taxe_Jouissance", "plan_etablie", "Usage_rec", "attestation_etablie")
 
df <- sonatur %>%
  select(all_of(vars_exp))

model <- lm( Superficie ~ . , data = df)
vif(model)

```

L‚Äôanalyse de la multicolin√©arit√© a √©t√© conduite √† l‚Äôaide du GVIF (Generalized Variance Inflation Factor). Les r√©sultats montrent que toutes les variables pr√©sentent un GVIF^(1/(2*Df)) inf√©rieur √† 2.5, seuil g√©n√©ralement admis pour d√©tecter une colin√©arit√© pr√©occupante. Bien que les variables Site_rec (2.08) et Taxe_Jouissance (2.03) affichent des valeurs l√©g√®rement sup√©rieures √† 2, elles restent dans une zone de vigilance acceptable, ne compromettant pas la stabilit√© des coefficients du mod√®le. Nous retenons donc ces variables pour la mod√©lisation.


## M√©thodologie

Cette section d√©crit la d√©marche adopt√©e pour estimer un indice d‚Äô√©volution des prix des parcelles entre 2018 et 2024 en utilisant une approche h√©donique.

### Approche g√©n√©rale

L‚Äôobjectif de cette √©tude est d‚Äôestimer un **indice d‚Äô√©volution des prix des parcelles** situ√©es dans la ville de Ouagadougou entre 2018 et 2024. Pour ce faire, nous utilisons la **m√©thode h√©donique**, qui repose sur l‚Äôid√©e que le prix d‚Äôun bien peut √™tre expliqu√© par ses caract√©ristiques observables (localisation, usage, superficie, etc.).

### Sp√©cification du mod√®le h√©donique

La variable d√©pendante retenue est le **co√ªt au m√®tre carr√©** (`Cout_m2`), ce qui permet de neutraliser l‚Äôeffet de la superficie. Le mod√®le h√©donique inclut :

- des variables quantitatives continues : `Superficie`, `Taxe_Jouissance` ;
- des variables qualitatives en facteurs : `Site_rec`, `Usage_rec`, `Type_option`, `plan_etablie`, `attestation_etablie` ;
- des variables temporelles repr√©sent√©es par des **dummies annuelles** (`Annee`), afin de capturer l‚Äôeffet de l‚Äôann√©e dans l‚Äô√©volution du prix.

Le mod√®le s‚Äô√©crit alors :

$$
\log(Cout\_m2_i) = \alpha + \sum_k \beta_k X_{ik} + \sum_t \gamma_t D_{it} + \varepsilon_i
$$

o√π :
- \( X_{ik} \) repr√©sente les caract√©ristiques du bien \( i \) ;
- \( D_{it} \) sont des indicatrices (dummies) temporelles ;
- \( \gamma_t \) est le coefficient repr√©sentant l‚Äôeffet de l‚Äôann√©e \( t \) ;
- \( \varepsilon_i \) est le terme d‚Äôerreur.

### V√©rification des hypoth√®ses du mod√®le lin√©aire

Avant de valider le mod√®le, plusieurs hypoth√®ses ont √©t√© test√©es :

- **Lin√©arit√©** entre les variables explicatives et la variable expliqu√©e (via graphiques de r√©sidus) ;
- **Normalit√© des r√©sidus** (`shapiro.test`) ;
- **Homoscedasticit√©** des erreurs (`bptest`) ;
- **Absence de multicolin√©arit√©** (`vif`) ;
- **Bonne sp√©cification du mod√®le** (`linktest`).

### Limites et recours √† des mod√®les alternatifs

Des tests ont r√©v√©l√© :

- une **non-normalit√© persistante** des r√©sidus ;
- des soup√ßons d‚Äô**h√©t√©rosc√©dasticit√©** ;
- des relations **non lin√©aires** avec certaines variables.

En r√©ponse, deux mod√®les alternatifs ont √©t√© mobilis√©s :

#### Mod√®le GAM (Generalized Additive Model)

Le **GAM** permet d'introduire des effets non lin√©aires sur certaines variables quantitatives (notamment `Superficie`) tout en gardant des effets param√©triques sur les variables qualitatives.

Le mod√®le prend la forme :

$$
\log(Cout\_m2_i) = \alpha + s_1(Superficie_i) + Taxe\_Jouissance_i + \sum_j \beta_j Z_{ij} + \varepsilon_i
$$

o√π \( s_1 \) est une fonction de lissage spline.

#### Mod√®le XGBoost avec dummies temporelles

Un **mod√®le XGBoost** a ensuite √©t√© construit afin de :

- mieux capter les non-lin√©arit√©s complexes et interactions ;
- r√©duire l‚Äôimpact des valeurs extr√™mes (outliers) ;
- et int√©grer les ann√©es comme **variables indicatrices** pour construire un **indice d‚Äô√©volution des prix**.

La **validation crois√©e** a √©t√© utilis√©e pour √©valuer la performance pr√©dictive du mod√®le, notamment en calculant des m√©triques comme le **RMSE** et le **R¬≤** pour chaque ann√©e.


## Mod√©lisation

### Mod√®le lin√©aire classique
Pour construire un mod√®le h√©donique de base, nous utilisons une r√©gression lin√©aire multiple, une m√©thode statistique simple et largement utilis√©e. L‚Äôid√©e est que le prix d‚Äôune parcelle peut √™tre exprim√© comme une combinaison lin√©aire de ses caract√©ristiques, ajust√©e par des effets temporels. 
Les dummies temporelles capturent les variations des prix d‚Äôune ann√©e √† l‚Äôautre. Le mod√®le est estim√© avec la fonction `lm` en R, et les pr√©dictions sont agr√©g√©es par ann√©e pour calculer un indice, normalis√© √† 100 pour 2018:

$$ \text{Indice}_t = \exp(\hat{\delta}_t) \times 100 $$

#### - Estimation

Construction du mod√®le
```{r, echo=TRUE, warning=FALSE}
# Construire le mod√®le lin√©aire h√©donique
models_data <- sonatur %>%
  dplyr::select(dplyr :: all_of(c("Cout_m2",vars_exp)))

model_linear <- lm(Cout_m2 ~ . , data = models_data )
# Afficher le r√©sum√© du mod√®le
#summary(model_linear)
```

Indices estim√©s :
```{r, echo=FALSE, warning=FALSE}
# Calculer les pr√©dictions
sonatur$pred_linear <- predict(model_linear, newdata = sonatur)

# Calculer l'indice (normalis√© par 2018)
indice_linear <- aggregate(pred_linear ~ Annee, data = sonatur, FUN = mean)
indice_linear$indice <- (indice_linear$pred_linear / indice_linear$pred_linear[indice_linear$Annee == "2018"]) * 100


# Donn√©es de d√©part
df <- tibble::tibble(
  Annee = as.factor(indice_linear$Annee),
  indice = indice_linear$indice)


# Ajouter la variation en pourcentage (ann√©e par rapport √† l‚Äôann√©e pr√©c√©dente)
df <- df %>%
  arrange(Annee) %>%
  mutate(Variation = c(NA, round((indice[-1] / indice[-length(indice)] - 1) * 100, 2)))
        
# Creation du tableau kable
kable(df, digits = 2,
      caption = "Indice des prix des parcelles predit par le mod√®le lin√©aire",
      col.names = c("Ann√©e", "Indice (base 100 en 2018)", "Variation annuelle (%)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE,
                font_size = 12)


```

#### - Verification des hypoth√®ses
```{r, echo=FALSE, warning=FALSE}


# Fonction de diagnostic
diagnostic_linear_model <- function(model, data, target_var, feature_vars) {
  # Pr√©parer les r√©sidus et pr√©dictions
  residuals <- residuals(model)
  fitted_values <- fitted(model)
  
  # 1. Test de lin√©arit√©
  linearity_plot <- "Graphique des r√©sidus vs pr√©dictions (voir ci-dessous)"
  linearity_result <- "Visuel (pas de test statistique formel)"
  linearity_interp <- if (any(abs(residuals) > mean(abs(residuals)) * 3)) 
    "Pr√©sence possible de motifs non lin√©aires (√©carts notables)" 
    else "Aucun motif √©vident de non-lin√©arit√©"

  # 2. Test d'homosc√©dasticit√© (Breusch-Pagan)
  bp_test <- bptest(model)
  bp_result <- paste("p-value =", round(bp_test$p.value, 4))
  bp_interp <- if (bp_test$p.value < 0.05) 
    "Rejet de l'homosc√©dasticit√© (variance non constante)" 
    else "Hypoth√®se d'homosc√©dasticit√© non rejet√©e"

  # 3. Test de normalit√© des r√©sidus (Shapiro-Wilk)
  shapiro_test <- shapiro.test(residuals)
  shapiro_result <- paste("p-value =", round(shapiro_test$p.value, 4))
  shapiro_interp <- if (shapiro_test$p.value < 0.05) 
    "Rejet de la normalit√© des r√©sidus" 
    else "Normalit√© des r√©sidus non rejet√©e"

  # 4. Test d'absence de multicolin√©arit√© (VIF)
  vif_values <- as.data.frame(vif(model))
  vif_result <- paste("VIF max =", round(max(vif_values$`GVIF^(1/(2*Df))`), 2))
  vif_interp <- if (max(vif_values$`GVIF^(1/(2*Df))`) > 5) 
    "Multicolin√©arit√© probl√©matique d√©tect√©e (VIF > 5)" 
    else "Aucune multicolin√©arit√© significative"

  # Cr√©er un data frame avec les r√©sultats
  results_df <- data.frame(
    "Type de test" = c("Lin√©arit√©", "Homosc√©dasticit√©", "Normalit√© des r√©sidus", "Multicolin√©arit√©"),
    "R√©sultats" = c(linearity_result, bp_result, shapiro_result, vif_result),
    "Interpr√©tation" = c(linearity_interp, bp_interp, shapiro_interp, vif_interp)
  )

 # Creation du tableau kable
  
  kable_table<- kable(as.data.frame(results_df), digits = 2,
      caption = "R√©sum√© des diagnostics du mod√®le lm",
      col.names = c("Type de test", "R√©sultat", "Interpr√©tation")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE,
                font_size = 12)
  
  # Retourner le tableau
  return(kable_table)
}

# Appliquer la fonction
target_var <- "Cout_m2"
diagnostic_result <- diagnostic_linear_model(model_linear, sonatur, target_var, vars_exp)

# affichage des resultats
diagnostic_result
```
 
 
```{r, echo=FALSE,warning=FALSE}
residuals <- residuals(model_linear)
  fitted_values <- fitted(model_linear)
plt <- plot(fitted_values, residuals, xlab = "Pr√©dictions", ylab = "R√©sidus",
       main = "R√©sidus vs Pr√©dictions (Lin√©arit√©)")
  abline(h = 0, col = "red")
```
 
Le diagnostic visuel des r√©sidus en fonction des valeurs ajust√©es (graphique R√©sidus vs Pr√©dictions) met en √©vidence une violation de l‚Äôhypoth√®se de lin√©arit√©. En effet, la distribution des r√©sidus montre une structure incurv√©e, sugg√©rant que la relation entre les variables explicatives et la variable expliqu√©e n‚Äôest pas strictement lin√©aire. Ce r√©sultat plaide en faveur de l'exploration de mod√®les alternatifs plus flexibles ou robustes, comme la r√©gression quantile, les splines ou les mod√®les non param√©triques.

Compte tenu de la non-lin√©arit√© et l'h√©t√©rosc√©dasticit√© d√©tect√©e dans le mod√®le lin√©aire classique, une alternative a √©t√© propos√©e via la mod√©lisation additive g√©n√©ralis√©e (GAM). Ce mod√®le permet d‚Äôestimer de mani√®re flexible les effets des variables continues comme la superficie et l‚Äôann√©e, sans imposer une forme fonctionnelle stricte. Les r√©sultats montrent une am√©lioration de l‚Äôajustement et confirment la pertinence de cette approche pour mod√©liser la formation des prix fonciers.


### Le mod√®le additif g√©n√©ralis√© (GAM)
#### - Estimation
Construction du mod√®le
```{r, echo=TRUE,warning=FALSE}

# Mod√®le avec GAM
# On applique une fonction lisse (spline) √† Superficie et √† Annee
modele_gam <- gam(Cout_m2 ~ s(Superficie) + Taxe_Jouissance + Annee + Type_option +
                    Usage_rec + Site_rec + plan_etablie +attestation_etablie, 
                  data = sonatur)
```

#### - V√©rification des hypoth√®ses 
```{r,fig.width=6, fig.height=4, out.width="\\linewidth", fig.align="center", echo=FALSE, warning=FALSE}
diagnostic_modele_gam_complet <- function(modele) {
  # R√©sidus et pr√©dictions
  res <- residuals(modele)
  yhat <- fitted(modele)

  # 1. Normalit√© des r√©sidus
  test_norm <- shapiro.test(res)
  norm_result <- c(
    "Test de normalit√© des r√©sidus (Shapiro-Wilk)",
    paste0("W = ", round(test_norm$statistic, 3), ", p = ", format.pval(test_norm$p.value, digits = 3)),
    ifelse(test_norm$p.value < 0.05, "R√©sidus non normalement distribu√©s", "R√©sidus normalement distribu√©s")
  )

  # 2. H√©t√©rosc√©dasticit√©
  bp_test <- tryCatch({
    bptest(gam(formula(modele), data = modele$model, method = "ML"))
  }, error = function(e) NULL)

  hetero_result <- if (!is.null(bp_test)) {
    c("Test de Breusch-Pagan (h√©t√©rosc√©dasticit√©)",
      paste0("BP = ", round(bp_test$statistic, 3), ", p = ", format.pval(bp_test$p.value, digits = 3)),
      ifelse(bp_test$p.value < 0.05, "Pr√©sence d'h√©t√©rosc√©dasticit√©", "Homosc√©dasticit√©"))
  } else {
    c("Test de Breusch-Pagan", "N/A", "Non applicable au mod√®le GAM directement")
  }

  # 3. Skewness
  skew <- moments::skewness(res)
  skew_result <- c(
    "Asym√©trie des r√©sidus",
    paste("Skewness =", round(skew, 2)),
    ifelse(abs(skew) > 1, "R√©sidus fortement asym√©triques", "Asym√©trie mod√©r√©e ou nulle")
  )

  # 4. Effets liss√©s
  k_check <- summary(modele)$s.table
  lin_result <- c(
    "Test de lin√©arit√© (edf des splines)",
    paste0("edf = ", paste(round(k_check[,"edf"], 2), collapse = ", ")),
    ifelse(any(k_check[,"edf"] > 1.5), "Non-lin√©arit√© d√©tect√©e", "Effets proches du lin√©aire")
  )

  linktest_result <- c("Test de sp√©cification (Link test)", "N/A", "Non applicable au mod√®le GAM")

  tableau <- rbind(norm_result, hetero_result, skew_result, lin_result, linktest_result)
  colnames(tableau) <- c("Type de test", "R√©sultat", "Interpr√©tation")

  kable_table<- kable(as.data.frame(tableau), digits = 2,
      caption = "R√©sum√© des diagnostics du mod√®le GAM",
      col.names = c("Type de test", "R√©sultat", "Interpr√©tation")) %>%
  kable_styling(latex_options = c("striped", "scale_down"), font_size = 12)
  
  return(kable_table)
}

#Appel de la fonction de diagnostique
diagnostic_modele_gam_complet(modele_gam)
```



```{r, echo=FALSE, warning=FALSE}
res <- residuals(modele_gam)
yhat <- fitted(modele_gam)
##  Graphiques combin√©s
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # 2x2 grille, marges

# 1. R√©sidus vs pr√©dictions
plot(yhat, res, 
     main = "R√©sidus vs Pr√©dictions", xlab = "Pr√©dictions", ylab = "R√©sidus", col = "blue", pch = 20)
abline(h = 0, col = "red")

# 2. Histogramme des r√©sidus
hist(res, breaks = 20, main = "Histogramme des r√©sidus", xlab = "R√©sidus", col = "lightblue")

# 3. QQ-plot
qqnorm(res, main = "QQ-plot des r√©sidus", pch = 20, col = "blue")
qqline(res, col = "red")

# 4. Premier effet spline
plot(modele_gam, select = 1, shade = TRUE, main = "Effet spline : 1er terme")

# R√©initialiser
par(mfrow = c(1, 1))
```

Les diagnostics r√©alis√©s sur le mod√®le GAM ont mis en √©vidence certaines limites dans la validit√© des hypoth√®ses classiques de la r√©gression. En particulier, les r√©sidus pr√©sentent une distribution asym√©trique et des √©carts aux quantiles th√©oriques, remettant en cause l‚Äôhypoth√®se de normalit√©. De plus, l‚Äôeffet de la superficie sur le prix au m√®tre carr√© n‚Äôest pas lin√©aire, mais a pu √™tre mod√©lis√© ad√©quatement via un effet spline. Ces r√©sultats confirment la pertinence d‚Äôun mod√®le semi-param√©trique tel que le GAM, mais sugg√®rent √©galement que des approches plus flexibles et robustes pourraient mieux capturer les structures complexes et les √©ventuelles interactions non lin√©aires pr√©sentes dans les donn√©es.

  Afin de pallier les limites observ√©es dans le mod√®le pr√©c√©dent, notamment en ce qui concerne les hypoth√®ses de normalit√©, de lin√©arit√© et d'h√©teroscedasticit√©, nous avons opt√© pour une mod√©lisation alternative reposant sur des techniques d‚Äôapprentissage automatique. 

### M√©thode des dummies temporelles avec le mod√®le d‚Äôamplification de gradient (Gradient Boosting)

#### - Pr√©sentation du mod√®le
Face aux limites des mod√®les lin√©aires, une alternative plus robuste est adopt√©e : le mod√®le d‚Äôamplification de gradient (Gradient Boosting) avec XGBoost. Cette m√©thode d‚Äôapprentissage automatique est choisie pour sa capacit√© √† capturer des relations non lin√©aires et des interactions complexes entre les variables, sans exiger les m√™mes hypoth√®ses strictes que la r√©gression lin√©aire. Le processus comprend :
- **Entra√Ænement** : Le mod√®le XGBoost est entra√Æn√© sur toutes les donn√©es avec les m√™mes variables explicatives, en utilisant la fonction `xgb.train` en R. Les hyperparam√®tres (nombre d‚Äôit√©rations, profondeur des arbres, taux d‚Äôapprentissage) sont optimis√©s via une recherche par grille avec `caret`.
- **Construction de l‚Äôindice** : Les pr√©dictions du mod√®le sont agr√©g√©es par ann√©e, et un indice est calcul√© en normalisant par rapport √† 2018, similaire √† l‚Äôapproche lin√©aire.
- **Validation** : La performance est √©valu√©e avec une validation crois√©e temporelle et globale, calculant la RMSE et le $$( R^2 )$$ pour mesurer la pr√©cision et la g√©n√©ralisation. La robustesse est test√©e en perturbant l√©g√®rement les caract√©ristiques (10 % de `Superficie`) pour √©valuer la sensibilit√© de l‚Äôindice. 

#### - La construction du mod√®le
Le code √©tant long, nous avons ignor√© cette partie dans ce rapport mais vous pouvez retrouver l'integralit√© de cette partie dans le script Rmd.
```{r, results='hide', message=FALSE, warning=FALSE, echo=FALSE}

feature_vars <- vars_exp
prepare_xgb_data <- function(df, feature_vars, model_feature_names = NULL) {
  design_matrix <- model.matrix(~ . -1, data = df[, feature_vars, drop = FALSE])
  
  #design_matrix <- design_matrix[, model_feature_names]
  return(design_matrix)
}

# Pr√©paration des donn√©es d'entra√Ænement

# --- Cr√©ation de la matrice de features sans intercept
#feature_vars = c( "Superficie","Taxe_Jouissance", "plan_etablie","Usage_rec", "Annee")
#dmat <- sparse.model.matrix(~ Superficie + Taxe_Jouissance + plan_etablie + Usage_rec + Annee - 1, data = sonatur)

dmat <- prepare_xgb_data(sonatur, feature_vars)

# 2. Enregistrer les noms des variables/features utilis√©es
model_features <- colnames(dmat)

# 3. Enregistrer dans un fichier .rds (vous pouvez changer le chemin)
saveRDS(model_features, "xgb_model_features.rds")

y <- sonatur$Cout_m2 # 
x <- as.data.frame(as.matrix(dmat)) # les labels

# --- Cr√©ation du DMatrix XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(dmat), label = sonatur$Cout_m2)

# --- Param√®tres XGBoost
# --- Param√®tres XGBoost
params <- list(
  booster = "gbtree",
  objective = "reg:squarederror",
  eval_metric = "rmse",
  eta = 0.1,
  max_depth = 6,
  subsample = 0.8,
  colsample_bytree = 0.8
)

set.seed(42)

# --- Validation crois√©e
cv_model <- xgb.cv(
  params = params,
  data = dtrain,
  nrounds = 1000,
  nfold = 5,
  early_stopping_rounds = 10,
  verbose = 1
)

best_nrounds <- cv_model$best_iteration
cat("Nombre optimal de boosting rounds :", best_nrounds, "\n")


# --- Entra√Ænement final
xgb_model <- xgboost(
  data = dtrain,
  params = params,
  nrounds = best_nrounds,
  verbose = 0
)

# --- Pr√©dictions
pred_log <- predict(xgb_model, dtrain)

sonatur$pred_log <- pred_log

residuals <- pred_log - sonatur$Cout_m2

```

#### - Calcul de l'indice de prix base 2018

```{r, echo=FALSE, warning=FALSE}

# --- Calcul de l‚Äôindice h√©donique
indice_td <- aggregate(pred_log ~ Annee, data = sonatur, FUN = mean)

# --- V√©rification de l‚Äôann√©e de r√©f√©rence
if (!"2018" %in% indice_td$Annee) {
  stop("L'ann√©e de r√©f√©rence 2018 n'est pas pr√©sente dans les donn√©es.")
}

# --- Transformation en base 100 (ann√©e 2018)
indice_td$indice <- exp(indice_td$pred_log - indice_td$pred_log[indice_td$Annee == "2018"]) * 100

# Synth√®se dans le tableau kable

# Donn√©es de d√©part
df <- tibble::tibble(
  Annee = as.factor(indice_td$Annee),
  indice = indice_td$indice)


# Ajouter la variation en pourcentage (ann√©e par rapport √† l‚Äôann√©e pr√©c√©dente)
df <- df %>%
  arrange(Annee) %>%
  mutate(Variation = c(NA, round((indice[-1] / indice[-length(indice)] - 1) * 100, 2)))
        
# Creation du tableau kable
kable(df, digits = 2,
      caption = "Indice des prix des parcelles predit par le mod√®le lin√©aire",
      col.names = c("Ann√©e", "Indice (base 100 en 2018)", "Variation annuelle (%)")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                full_width = FALSE,
                font_size = 12)


```

Nous allons diagnostiqu√© le mod√®le avant de revenir sur l'interpr√©tation des indices calcul√©s.

#### - Diagnostique du mod√®le

Cette diagnostique se fera en trois points : 
La validation crois√©e (pour confirmer la fiabilit√© du mod√®le h√©donique retenu),V√©rifier les r√©sidus (pour v√©rifier la stabilit√© du mod√®le au fil des ann√©es) et le tester de robustesse.

##### a. Validation crois√©e

```{r, echo=FALSE, warning=FALSE, message=FALSE}
diagnostic_with_trained_model <- function(model, data, target_var, feature_vars, time_var, nfolds = 5) {

  # Nettoyage
  data <- data[complete.cases(data[, c(target_var, feature_vars, time_var)]), ]
  
  # Cr√©ation des matrices
  dmat <- sparse.model.matrix(as.formula(paste("~", paste(feature_vars, collapse = " + "), "- 1")), data = data)
  dtrain_all <- xgb.DMatrix(data = as.matrix(dmat), label = data[[target_var]])
  
  # Pr√©diction globale
  pred_global <- predict(model, dtrain_all)
  actual_global <- data[[target_var]]
  rmse_global <- sqrt(mean((pred_global - actual_global)^2))
  r2_global <- 1 - sum((actual_global - pred_global)^2) / sum((actual_global - mean(actual_global))^2)
  
  # Validation temporelle par ann√©e
  years <- sort(unique(data[[time_var]]))
  rmse_year <- numeric(length(years))
  r2_year <- numeric(length(years))
  
  for (i in seq_along(years)) {
    year_data <- data[data[[time_var]] == years[i], ]
    if (nrow(year_data) < 5) next  # Trop peu d'observations

    dmat_test <- sparse.model.matrix(as.formula(paste("~", paste(feature_vars, collapse = " + "), "- 1")), data = year_data)
    dtest <- xgb.DMatrix(data = as.matrix(dmat_test))
    pred <- predict(model, dtest)
    actual <- year_data[[target_var]]
    
    rmse_year[i] <- sqrt(mean((pred - actual)^2))
    ss_tot <- sum((actual - mean(actual))^2)
    ss_res <- sum((actual - pred)^2)
    r2_year[i] <- if (ss_tot > 0) 1 - ss_res / ss_tot else NA
  }
  
  # Interpr√©tation
  interpretation <- sapply(r2_year, function(r2) {
    if (is.na(r2)) return("Insuffisant")
    else if (r2 >= 0.7) "Tr√®s bon ajustement"
    else if (r2 >= 0.5) "Ajustement acceptable"
    else "Faible ajustement"
  })
  
  # Cr√©ation du tableau
  table_results <- data.frame(
    Annee = years,
    RMSE = round(rmse_year, 2),
    R2 = round(r2_year, 3),
    Interpretation = interpretation
  )
  
  # Affichage kable
  kable(table_results, caption = "Performance du mod√®le XGBoost par ann√©e",
        col.names = c("Ann√©e", "RMSE", "R¬≤", "Interpr√©tation"), align = "c") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                  full_width = FALSE, font_size = 12)
}

target_var <- 'Cout_m2'
time_var <- 'Annee'
diagnostic_with_trained_model(xgb_model, sonatur, target_var, feature_vars, time_var, nfolds = 5)
```

L'analyse des performances du mod√®le XGBoost sur la p√©riode 2018-2024 r√©v√®le une excellente capacit√© d'ajustement global, comme en t√©moigne la valeur √©lev√©e et constante du coefficient de d√©termination ($ R^2 $), oscillant entre 0.867 et 0.996. Cette stabilit√© indique que le mod√®le capture efficacement la variabilit√© des prix des parcelles en fonction des caract√©ristiques consid√©r√©es (superficie, usage, type d'option, localisation, et ann√©e). La RMSE, qui mesure l'erreur moyenne, diminue progressivement au fil des ann√©es, passant de 0.17 en 2018 √† un remarquable 0.01 en 2024, sugg√©rant une pr√©cision croissante des pr√©dictions, potentiellement due √† une homog√©n√©it√© accrue des donn√©es ou √† un meilleur apprentissage par le mod√®le au fil du temps. Les $ R^2 $ sup√©rieurs √† 0.9 √† partir de 2021, combin√©s √† des RMSE tr√®s faibles (notamment 0.01 en 2024), refl√®tent un tr√®s bon ajustement, bien que cette performance exceptionnelle en 2024 pourrait √©galement indiquer un surapprentissage ou un √©chantillon r√©duit (69 observations). Globalement, le mod√®le d√©montre une robustesse remarquable, mais une analyse approfondie des r√©sidus et des donn√©es de 2024 serait utile pour valider sa g√©n√©ralisation.


##### b. V√©rification des r√©sidus

Calculez les pr√©dictions pour chaque ann√©e et comparez-les aux valeurs r√©elles :

```{r, echo=FALSE, warning=FALSE, message=FALSE}


boxplot(residuals ~ sonatur$Annee, main = "R√©sidus par ann√©e", ylab = "R√©sidus")

```

 Le mod√®le XGBoost semble offrir une bonne stabilit√© temporelle de ses performances, sans biais majeur au fil des ann√©es. Toutefois, une vigilance est requise pour les ann√©es les plus r√©centes (2023‚Äì2024), qui pr√©sentent soit des pr√©dictions trop proches de la moyenne (manque de variabilit√©), soit des erreurs ponctuelles importantes (pr√©sence d‚Äôoutliers). Cela peut indiquer un besoin de renforcement des donn√©es r√©centes, ou une √©volution structurelle non captur√©e par les variables explicatives du mod√®le.



##### c. Tester la robustesse

Il s'agit de perturber une caract√©ristique intrins√®que √† la variable expliqu√© et recalculer les indices de prix et comparer avec les indices pr√©dits plus haut. Pour cela nous allons augmenter la superficie de 10%.

```{r,echo=FALSE, message=FALSE, warning=FALSE}
sonatur_perturbed <- sonatur
sonatur_perturbed$Superficie <- sonatur_perturbed$Superficie * 1.1
dmat_perturbed <- sparse.model.matrix(~ Superficie + Usage_rec + Site_rec + Annee - 1, data = sonatur_perturbed)

dtrain_perturbed <- xgb.DMatrix(data = as.matrix(dmat_perturbed), label = sonatur_perturbed$Cout_m2)

model_perturbed <- xgb.train(data = dtrain_perturbed, nrounds = 100, objective = "reg:squarederror")

pred_perturbed <- predict(model_perturbed, dtrain_perturbed)

sonatur_perturbed$pred_log <- pred_perturbed

indice_perturbed <- aggregate(pred_log ~ Annee, data = sonatur_perturbed, FUN = mean)

indice_perturbed$indice <- exp(indice_perturbed$pred_log - indice_perturbed$pred_log[indice_perturbed$Annee == "2018"]) * 100

# preparation pour la visualisation
indice_reel_plot <- indice_perturbed %>%
  select(Annee, indice_perturbed = indice)

indice_modele_plot <- indice_td %>%
  select(Annee, indice_model = indice)

# Fusionner les deux indices
comparaison_indices <- full_join(indice_reel_plot, indice_modele_plot, by = "Annee") %>%
  pivot_longer(cols = c("indice_perturbed", "indice_model"),
               names_to = "Type", values_to = "Indice")

# Tracer les courbes
ggplot(comparaison_indices, aes(x = as.factor(Annee), y = Indice, group = Type, color = Type)) +
  geom_line(size = 1.3) +
  geom_point(size = 2) +
  scale_color_manual(values = c("indice_perturbed" = "steelblue", "indice_model" = "darkorange"),
                     labels = c("indice_perturbed ", "Indice estim√© (mod√®le)")) +
  labs(
    title = "√âvolution des indices de prix des parcelles (2018‚Äì2024)",
    subtitle = "Comparaison entre indice empirique et indice estim√© par mod√®le h√©donique",
    x = "Ann√©e",
    y = "Indice (base 100 en 2018)",
    color = "Source"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

#print(indice_perturbed$indice)
```

Le test de perturbation (+1O% de superficie) d√©montre une robustesse remarquable du mod√®le, comme en attestent les observations cl√©s suivantes :  
   Les courbes de l'indice original et de l'indice perturb√© (`indice_perturbed`) restent √©troitement align√©es sur toute la p√©riode (2018-2024). L'√©cart maximal n'exc√®de pas **2 points d'indice** (~103 vs ~105 en 2019), ce qui est n√©gligeable dans un contexte √©conomique. Cette proximit√© confirme que le mod√®le r√©siste aux variations mineures des donn√©es d'entr√©e.
   Bien que la superficie soit un d√©terminant th√©orique majeur des prix fonciers, son augmentation de 11% n'a pas provoqu√© de distorsion significative. 
  




#### - Interpretation des r√©sultats 
#####  Les indices
```{r,fig.width=6, fig.height=4, out.width="\\linewidth", fig.align="center", echo=FALSE, warning=FALSE, message=FALSE}
# Extraire les ann√©es et les indices
years <- as.numeric(as.character(indice_td$Annee))
indice_values <- indice_td$indice

# Tracer l'indice
plot(years, indice_values, type = "b", pch = 19, col = "blue",
     xlab = "Ann√©e", ylab = "Indice des prix (base 2018 = 100)",
     main = "√âvolution de l'Indice des Prix Immobiliers (2018-2024)",
     ylim = c(0, max(indice_values) * 1.1))  # Ajuster l'√©chelle
grid()  # Ajouter une grille
text(years, indice_values, labels = round(indice_values, 1), pos = 3, cex = 0.8)

```
Le graphique met en √©vidence une √©volution instable de l‚Äôindice des prix immobiliers √† Ouagadougou entre 2018 et 2024. Apr√®s une l√©g√®re hausse entre 2018 (base 100) et 2019 (100,4), les prix connaissent une baisse progressive jusqu‚Äôen 2021 (87,9), traduisant un ralentissement du march√© immobilier, possiblement li√© √† des facteurs √©conomiques ou contextuels comme la crise sanitaire. En 2022, l‚Äôindice bondit fortement √† 116,1, signalant un pic des prix, peut-√™tre d√ª √† une pression sp√©culative ou √† une offre insuffisante. Cependant, cette hausse est suivie d‚Äôun net recul en 2023 (80,7) et d‚Äôune stabilisation √† un niveau bas en 2024 (80,1), illustrant un retournement du march√©. Cette volatilit√© sugg√®re des dynamiques fonci√®res sensibles aux chocs et appelle √† une r√©gulation adapt√©e pour stabiliser le secteur immobilier.

#####  L'importance des variables 
```{r, echo=FALSE,message=FALSE,warning=FALSE}

# R√©cup√©rer l‚Äôimportance
importance_matrix <- xgb.importance(model = xgb_model)

# Afficher dans un tableau kable
kable(importance_matrix, digits = 3, caption = "Importance des variables dans le mod√®le XGBoost")

```

La variable Superficie se distingue nettement avec un Gain de 0.378, un Cover de 0.428 et une Fr√©quence de 0.416. Elle constitue de loin le facteur explicatif le plus d√©terminant du prix au m√®tre carr√©, ce qui corrobore l‚Äôintuition selon laquelle la taille de la parcelle influence fortement sa valorisation.

Taxe_Jouissance arrive en deuxi√®me position avec un Gain de 0.224. Bien qu‚Äôelle soit moins fr√©quemment utilis√©e, son effet sur la pr√©diction reste substantiel, sugg√©rant qu‚Äôelle agit comme un facteur compl√©mentaire important dans la formation des prix.

Les modalit√©s du Type_option telles que "ACOMPTE 30%" ou "ACOMPTE 50%" apparaissent √©galement avec des contributions significatives. Cela refl√®te le fait que les modalit√©s de paiement influencent les prix observ√©s, probablement en lien avec les conditions d‚Äôaccessibilit√© ou de sp√©culation.

Les variables temporelles (Annee2023, Annee2021, etc.), bien que faiblement fr√©quentes, contribuent non n√©gligeablement √† la performance du mod√®le. Cela justifie l‚Äôinclusion des dummies temporelles dans une perspective d‚Äôestimation d‚Äôun indice h√©donique d‚Äô√©volution des prix.

Les variables li√©es √† l‚Äôusage (Usage_rec) et au site (Site_rec) ont des effets plus localis√©s et modestes mais non n√©gligeables, traduisant l‚Äôh√©t√©rog√©n√©it√© spatiale et fonctionnelle du march√© foncier urbain √† Ouagadougou.

Enfin, certaines modalit√©s comme Site_recSILMIOUGOU ou Annee2022 pr√©sentent des contributions quasi nulles (Gain < 0.005), ce qui sugg√®re qu‚Äôelles n‚Äôam√©liorent pas significativement la qualit√© pr√©dictive du mod√®le. Elles pourraient √™tre exclues lors d‚Äôune phase de simplification.

##### Comparaison 

Calculez un indice brut bas√© sur la moyenne des prix r√©els par ann√©e :


```{r,echo=FALSE, message=FALSE,warning=FALSE}

indice_reel <- aggregate(Cout_m2 ~ Annee, data = sonatur, FUN = mean, na.rm = TRUE) #indice construit sans effets

indice_reel$indice <- (indice_reel$Cout_m2 / indice_reel$Cout_m2[indice_reel$Annee == "2018"]) * 100



# S'assurer que les noms de colonnes sont harmonis√©s
indice_reel_plot <- indice_reel %>%
  select(Annee, indice_reel = indice)

indice_modele_plot <- indice_td %>%
  select(Annee, indice_model = indice)

# Fusionner les deux indices
comparaison_indices <- full_join(indice_reel_plot, indice_modele_plot, by = "Annee") %>%
  pivot_longer(cols = c("indice_reel", "indice_model"),
               names_to = "Type", values_to = "Indice")

# Tracer les courbes
ggplot(comparaison_indices, aes(x = as.factor(Annee), y = Indice, group = Type, color = Type)) +
  geom_line(size = 1.3) +
  geom_point(size = 2) +
  scale_color_manual(values = c("indice_reel" = "steelblue", "indice_model" = "darkorange"),
                     labels = c("Indice r√©el (moyenne annuelle)", "Indice estim√© (mod√®le)")) +
  labs(
    title = "√âvolution des indices de prix des parcelles (2018‚Äì2024)",
    subtitle = "Comparaison entre indice empirique et indice estim√© par mod√®le h√©donique",
    x = "Ann√©e",
    y = "Indice (base 100 en 2018)",
    color = "Source"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

```

Le graphique ci-dessus met en parall√®le l‚Äô√©volution de l‚Äôindice de prix moyen des parcelles (indice r√©el) avec l‚Äôindice estim√© par le mod√®le h√©donique √† dummies temporelles.

On observe que les deux courbes pr√©sentent une dynamique relativement similaire, traduisant la capacit√© du mod√®le √† capturer l‚Äô√©volution structurelle des prix sur la p√©riode 2018‚Äì2024.
Les √©carts ponctuels peuvent s'expliquer par des effets sp√©cifiques non int√©gr√©s dans le mod√®le (par exemple : effets de localisation fine, politiques fonci√®res ponctuelles, ou caract√©ristiques non observ√©es).

## Conclusion
Cette √©tude visait √† estimer un indice h√©donique de l‚Äô√©volution des prix des parcelles √† Ouagadougou entre 2018 et 2024 √† partir des donn√©es de transactions fonci√®res. En mobilisant la m√©thode h√©donique, nous avons pu mod√©liser les prix unitaires des parcelles √† l‚Äôaide de variables d√©crivant leurs caract√©ristiques physiques, juridiques, contractuelles et temporelles.

Apr√®s avoir test√© un mod√®le lin√©aire classique, nous avons constat√© que plusieurs hypoth√®ses fondamentales (normalit√©, homosc√©dasticit√©, lin√©arit√©) n‚Äô√©taient pas satisfaites. En r√©ponse √† cela, nous avons opt√© pour un mod√®le plus flexible et robuste, notamment √† travers l‚Äôutilisation du mod√®le XGBoost avec dummies temporelles, qui a permis une meilleure prise en compte des non-lin√©arit√©s et des interactions complexes entre variables.

L‚Äôanalyse des r√©sidus, des valeurs pr√©dictives, ainsi que des performances de validation crois√©e (globale et par ann√©e) ont confirm√© la stabilit√© et la qualit√© pr√©dictive du mod√®le retenu. Par ailleurs, la comparaison entre l‚Äôindice h√©donique pr√©dit et celui issu des moyennes simples a mis en √©vidence la valeur ajout√©e de l‚Äôapproche h√©donique pour neutraliser les effets de composition et mieux refl√©ter l‚Äô√©volution "pure" des prix.

Enfin, l‚Äô√©valuation de l‚Äôimportance des variables a r√©v√©l√© que les facteurs les plus influents sont la superficie, la taxe de jouissance et les conditions de paiement, tandis que les effets temporels capt√©s par les dummies d‚Äôann√©e ont permis de reconstituer une trajectoire coh√©rente des prix.