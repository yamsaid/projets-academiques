title = "Projection des modalités (ACM 2)")
# Affichage côte à côte
## Recodage de donnees$Site en donnees$Site_rec
sonatur$Site_rec <- sonatur$Site |>
fct_recode(
"SITE GROUPE" = "CISSIN 2020 - SITE G",
"SITE GROUPE" = "OUAGA 2000 - SITE A",
"SITE GROUPE" = "SECTEUR 16 OUAGA"
)## Recodage de donnees$Usage en donnees$Usage_rec
sonatur$Usage_rec <- sonatur$Usage |>
fct_recode(
"1" = "COMMERCE",
"3" = "COMMERCE  A L'ANGLE",
"2" = "COMMERCE ANGLE",
"1" = "COMMERCE ANGLE 1 BITUME",
"1" = "COMMERCE ANGLE 2 VOIES",
"3" = "COMMERCE ORDINAIRE ANGLE",
"2" = "COMMUNAUTAIRE",
"3" = "HABITATION",
"2" = "HABITATION ANGLE",
"2" = "STATION SERVICE"
)
# log des variables quanti
sonatur$Cout_m2 <- log(sonatur$Cout_m2)
sonatur$Superficie <- log(sonatur$Superficie)
sonatur$Taxe_Jouissance <- log(sonatur$Taxe_Jouissance)
sonatur$COUT <- log(sonatur$COUT)
#  Variables qualitatives à résumer
qual_vars <- c("Ville", "Site_rec", "Usage_rec", "Type_option",
"attestation_etablie", "plan_etablie",
"Presence_ONEA", "Presence_SONABEL")
# Resumé personnalisé
resumer_categorielle <- function(v) {
v <- as.character(v)
tab <- table(v)
prop <- prop.table(tab)
mode <- names(tab)[which.max(tab)]
mode_freq <- max(tab)
mode_pct <- round(100 * max(prop), 1)
na_count <- sum(is.na(v))
n_modalites <- length(tab)
c(Nb_modalites = n_modalites,
Modalite_dominante = mode,
Effectif = mode_freq,
Pourcentage = mode_pct,
Valeurs_manquantes = na_count)
}
# Appliquer la fonction à chaque variable
summary_quali <- t(sapply(sonatur[qual_vars], resumer_categorielle)) %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Variable")
# Affichage avec kable
kable(summary_quali, caption = "Résumé descriptif des variables qualitatives") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
full_width = FALSE, font_size = 11)
vars_exp = c("Superficie","Type_option", "Annee", "Site_rec", "Taxe_Jouissance", "plan_etablie", "Usage_rec", "attestation_etablie")
df <- sonatur %>%
select(all_of(vars_exp))
model <- lm( Superficie ~ . , data = df)
vif(model)
# Construire le modèle linéaire hédonique
models_data <- sonatur %>%
dplyr::select(dplyr :: all_of(c("Cout_m2",vars_exp)))
model_linear <- lm(Cout_m2 ~ . , data = models_data )
# Afficher le résumé du modèle
#summary(model_linear)
# Calculer les prédictions
sonatur$pred_linear <- predict(model_linear, newdata = sonatur)
# Calculer l'indice (normalisé par 2018)
indice_linear <- aggregate(pred_linear ~ Annee, data = sonatur, FUN = mean)
indice_linear$indice <- (indice_linear$pred_linear / indice_linear$pred_linear[indice_linear$Annee == "2018"]) * 100
# Données de départ
df <- tibble::tibble(
Annee = as.factor(indice_linear$Annee),
indice = indice_linear$indice)
# Ajouter la variation en pourcentage (année par rapport à l’année précédente)
df <- df %>%
arrange(Annee) %>%
mutate(Variation = c(NA, round((indice[-1] / indice[-length(indice)] - 1) * 100, 2)))
# Creation du tableau kable
kable(df, digits = 2,
caption = "Indice des prix des parcelles predit par le modèle linéaire",
col.names = c("Année", "Indice (base 100 en 2018)", "Variation annuelle (%)")) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
font_size = 12)
# Fonction de diagnostic
diagnostic_linear_model <- function(model, data, target_var, feature_vars) {
# Préparer les résidus et prédictions
residuals <- residuals(model)
fitted_values <- fitted(model)
# 1. Test de linéarité
linearity_plot <- "Graphique des résidus vs prédictions (voir ci-dessous)"
linearity_result <- "Visuel (pas de test statistique formel)"
linearity_interp <- if (any(abs(residuals) > mean(abs(residuals)) * 3))
"Présence possible de motifs non linéaires (écarts notables)"
else "Aucun motif évident de non-linéarité"
# 2. Test d'homoscédasticité (Breusch-Pagan)
bp_test <- bptest(model)
bp_result <- paste("p-value =", round(bp_test$p.value, 4))
bp_interp <- if (bp_test$p.value < 0.05)
"Rejet de l'homoscédasticité (variance non constante)"
else "Hypothèse d'homoscédasticité non rejetée"
# 3. Test de normalité des résidus (Shapiro-Wilk)
shapiro_test <- shapiro.test(residuals)
shapiro_result <- paste("p-value =", round(shapiro_test$p.value, 4))
shapiro_interp <- if (shapiro_test$p.value < 0.05)
"Rejet de la normalité des résidus"
else "Normalité des résidus non rejetée"
# 4. Test d'absence de multicolinéarité (VIF)
vif_values <- as.data.frame(vif(model))
vif_result <- paste("VIF max =", round(max(vif_values$`GVIF^(1/(2*Df))`), 2))
vif_interp <- if (max(vif_values$`GVIF^(1/(2*Df))`) > 5)
"Multicolinéarité problématique détectée (VIF > 5)"
else "Aucune multicolinéarité significative"
# Créer un data frame avec les résultats
results_df <- data.frame(
"Type de test" = c("Linéarité", "Homoscédasticité", "Normalité des résidus", "Multicolinéarité"),
"Résultats" = c(linearity_result, bp_result, shapiro_result, vif_result),
"Interprétation" = c(linearity_interp, bp_interp, shapiro_interp, vif_interp)
)
# Creation du tableau kable
kable_table<- kable(as.data.frame(results_df), digits = 2,
caption = "Résumé des diagnostics du modèle lm",
col.names = c("Type de test", "Résultat", "Interprétation")) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
font_size = 12)
# Retourner le tableau
return(kable_table)
}
# Appliquer la fonction
target_var <- "Cout_m2"
diagnostic_result <- diagnostic_linear_model(model_linear, sonatur, target_var, vars_exp)
# affichage des resultats
diagnostic_result
residuals <- residuals(model_linear)
fitted_values <- fitted(model_linear)
plt <- plot(fitted_values, residuals, xlab = "Prédictions", ylab = "Résidus",
main = "Résidus vs Prédictions (Linéarité)")
abline(h = 0, col = "red")
# Modèle avec GAM
# On applique une fonction lisse (spline) à Superficie et à Annee
modele_gam <- gam(Cout_m2 ~ s(Superficie) + Taxe_Jouissance + Annee + Type_option +
Usage_rec + Site_rec + plan_etablie +attestation_etablie,
data = sonatur)
diagnostic_modele_gam_complet <- function(modele) {
# Résidus et prédictions
res <- residuals(modele)
yhat <- fitted(modele)
# 1. Normalité des résidus
test_norm <- shapiro.test(res)
norm_result <- c(
"Test de normalité des résidus (Shapiro-Wilk)",
paste0("W = ", round(test_norm$statistic, 3), ", p = ", format.pval(test_norm$p.value, digits = 3)),
ifelse(test_norm$p.value < 0.05, "Résidus non normalement distribués", "Résidus normalement distribués")
)
# 2. Hétéroscédasticité
bp_test <- tryCatch({
bptest(gam(formula(modele), data = modele$model, method = "ML"))
}, error = function(e) NULL)
hetero_result <- if (!is.null(bp_test)) {
c("Test de Breusch-Pagan (hétéroscédasticité)",
paste0("BP = ", round(bp_test$statistic, 3), ", p = ", format.pval(bp_test$p.value, digits = 3)),
ifelse(bp_test$p.value < 0.05, "Présence d'hétéroscédasticité", "Homoscédasticité"))
} else {
c("Test de Breusch-Pagan", "N/A", "Non applicable au modèle GAM directement")
}
# 3. Skewness
skew <- moments::skewness(res)
skew_result <- c(
"Asymétrie des résidus",
paste("Skewness =", round(skew, 2)),
ifelse(abs(skew) > 1, "Résidus fortement asymétriques", "Asymétrie modérée ou nulle")
)
# 4. Effets lissés
k_check <- summary(modele)$s.table
lin_result <- c(
"Test de linéarité (edf des splines)",
paste0("edf = ", paste(round(k_check[,"edf"], 2), collapse = ", ")),
ifelse(any(k_check[,"edf"] > 1.5), "Non-linéarité détectée", "Effets proches du linéaire")
)
linktest_result <- c("Test de spécification (Link test)", "N/A", "Non applicable au modèle GAM")
tableau <- rbind(norm_result, hetero_result, skew_result, lin_result, linktest_result)
colnames(tableau) <- c("Type de test", "Résultat", "Interprétation")
kable_table<- kable(as.data.frame(tableau), digits = 2,
caption = "Résumé des diagnostics du modèle GAM",
col.names = c("Type de test", "Résultat", "Interprétation")) %>%
kable_styling(latex_options = c("striped", "scale_down"), font_size = 9)
return(kable_table)
}
#Appel de la fonction de diagnostique
diagnostic_modele_gam_complet(modele_gam)
res <- residuals(modele_gam)
yhat <- fitted(modele_gam)
##  Graphiques combinés
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # 2x2 grille, marges
# 1. Résidus vs prédictions
plot(yhat, res,
main = "Résidus vs Prédictions", xlab = "Prédictions", ylab = "Résidus", col = "blue", pch = 20)
abline(h = 0, col = "red")
# 2. Histogramme des résidus
hist(res, breaks = 20, main = "Histogramme des résidus", xlab = "Résidus", col = "lightblue")
# 3. QQ-plot
qqnorm(res, main = "QQ-plot des résidus", pch = 20, col = "blue")
qqline(res, col = "red")
# 4. Premier effet spline
plot(modele_gam, select = 1, shade = TRUE, main = "Effet spline : 1er terme")
# Réinitialiser
par(mfrow = c(1, 1))
feature_vars <- vars_exp
prepare_xgb_data <- function(df, feature_vars, model_feature_names = NULL) {
design_matrix <- model.matrix(~ . -1, data = df[, feature_vars, drop = FALSE])
#design_matrix <- design_matrix[, model_feature_names]
return(design_matrix)
}
# Préparation des données d'entraînement
# --- Création de la matrice de features sans intercept
#feature_vars = c( "Superficie","Taxe_Jouissance", "plan_etablie","Usage_rec", "Annee")
#dmat <- sparse.model.matrix(~ Superficie + Taxe_Jouissance + plan_etablie + Usage_rec + Annee - 1, data = sonatur)
dmat <- prepare_xgb_data(sonatur, feature_vars)
# 2. Enregistrer les noms des variables/features utilisées
model_features <- colnames(dmat)
# 3. Enregistrer dans un fichier .rds (vous pouvez changer le chemin)
saveRDS(model_features, "xgb_model_features.rds")
y <- sonatur$Cout_m2 #
x <- as.data.frame(as.matrix(dmat)) # les labels
# --- Création du DMatrix XGBoost
dtrain <- xgb.DMatrix(data = as.matrix(dmat), label = sonatur$Cout_m2)
# --- Paramètres XGBoost
params <- list(
booster = "gbtree",
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.1,
max_depth = 6,
subsample = 0.8,
colsample_bytree = 0.8
)
set.seed(42)
# --- Validation croisée
cv_model <- xgb.cv(
params = params,
data = dtrain,
nrounds = 1000,
nfold = 5,
early_stopping_rounds = 10,
verbose = 1
)
best_nrounds <- cv_model$best_iteration
cat("Nombre optimal de boosting rounds :", best_nrounds, "\n")
# --- Entraînement final
xgb_model <- xgboost(
data = dtrain,
params = params,
nrounds = best_nrounds,
verbose = 0
)
# --- Prédictions
pred_log <- predict(xgb_model, dtrain)
sonatur$pred_log <- pred_log
residuals <- pred_log - sonatur$Cout_m2
# --- Calcul de l’indice hédonique
indice_td <- aggregate(pred_log ~ Annee, data = sonatur, FUN = mean)
# --- Vérification de l’année de référence
if (!"2018" %in% indice_td$Annee) {
stop("L'année de référence 2018 n'est pas présente dans les données.")
}
# --- Transformation en base 100 (année 2018)
indice_td$indice <- exp(indice_td$pred_log - indice_td$pred_log[indice_td$Annee == "2018"]) * 100
# Synthèse dans le tableau kable
# Données de départ
df <- tibble::tibble(
Annee = as.factor(indice_td$Annee),
indice = indice_td$indice)
# Ajouter la variation en pourcentage (année par rapport à l’année précédente)
df <- df %>%
arrange(Annee) %>%
mutate(Variation = c(NA, round((indice[-1] / indice[-length(indice)] - 1) * 100, 2)))
# Creation du tableau kable
kable(df, digits = 2,
caption = "Indice des prix des parcelles predit par le modèle linéaire",
col.names = c("Année", "Indice (base 100 en 2018)", "Variation annuelle (%)")) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = FALSE,
font_size = 12)
diagnostic_with_trained_model <- function(model, data, target_var, feature_vars, time_var, nfolds = 5) {
# Nettoyage
data <- data[complete.cases(data[, c(target_var, feature_vars, time_var)]), ]
# Création des matrices
dmat <- sparse.model.matrix(as.formula(paste("~", paste(feature_vars, collapse = " + "), "- 1")), data = data)
dtrain_all <- xgb.DMatrix(data = as.matrix(dmat), label = data[[target_var]])
# Prédiction globale
pred_global <- predict(model, dtrain_all)
actual_global <- data[[target_var]]
rmse_global <- sqrt(mean((pred_global - actual_global)^2))
r2_global <- 1 - sum((actual_global - pred_global)^2) / sum((actual_global - mean(actual_global))^2)
# Validation temporelle par année
years <- sort(unique(data[[time_var]]))
rmse_year <- numeric(length(years))
r2_year <- numeric(length(years))
for (i in seq_along(years)) {
year_data <- data[data[[time_var]] == years[i], ]
if (nrow(year_data) < 5) next  # Trop peu d'observations
dmat_test <- sparse.model.matrix(as.formula(paste("~", paste(feature_vars, collapse = " + "), "- 1")), data = year_data)
dtest <- xgb.DMatrix(data = as.matrix(dmat_test))
pred <- predict(model, dtest)
actual <- year_data[[target_var]]
rmse_year[i] <- sqrt(mean((pred - actual)^2))
ss_tot <- sum((actual - mean(actual))^2)
ss_res <- sum((actual - pred)^2)
r2_year[i] <- if (ss_tot > 0) 1 - ss_res / ss_tot else NA
}
# Interprétation
interpretation <- sapply(r2_year, function(r2) {
if (is.na(r2)) return("Insuffisant")
else if (r2 >= 0.7) "Très bon ajustement"
else if (r2 >= 0.5) "Ajustement acceptable"
else "Faible ajustement"
})
# Création du tableau
table_results <- data.frame(
Annee = years,
RMSE = round(rmse_year, 2),
R2 = round(r2_year, 3),
Interpretation = interpretation
)
# Affichage kable
kable(table_results, caption = "Performance du modèle XGBoost par année",
col.names = c("Année", "RMSE", "R²", "Interprétation"), align = "c") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
full_width = FALSE, font_size = 12)
}
target_var <- 'Cout_m2'
time_var <- 'Annee'
diagnostic_with_trained_model(xgb_model, sonatur, target_var, feature_vars, time_var, nfolds = 5)
boxplot(residuals ~ sonatur$Annee, main = "Résidus par année", ylab = "Résidus")
sonatur_perturbed <- sonatur
sonatur_perturbed$Superficie <- sonatur_perturbed$Superficie * 1.1
dmat_perturbed <- sparse.model.matrix(~ Superficie + Usage_rec + Site_rec + Annee - 1, data = sonatur_perturbed)
dtrain_perturbed <- xgb.DMatrix(data = as.matrix(dmat_perturbed), label = sonatur_perturbed$Cout_m2)
model_perturbed <- xgb.train(data = dtrain_perturbed, nrounds = 100, objective = "reg:squarederror")
pred_perturbed <- predict(model_perturbed, dtrain_perturbed)
sonatur_perturbed$pred_log <- pred_perturbed
indice_perturbed <- aggregate(pred_log ~ Annee, data = sonatur_perturbed, FUN = mean)
indice_perturbed$indice <- exp(indice_perturbed$pred_log - indice_perturbed$pred_log[indice_perturbed$Annee == "2018"]) * 100
# preparation pour la visualisation
indice_reel_plot <- indice_perturbed %>%
select(Annee, indice_perturbed = indice)
indice_modele_plot <- indice_td %>%
select(Annee, indice_model = indice)
# Fusionner les deux indices
comparaison_indices <- full_join(indice_reel_plot, indice_modele_plot, by = "Annee") %>%
pivot_longer(cols = c("indice_perturbed", "indice_model"),
names_to = "Type", values_to = "Indice")
# Tracer les courbes
ggplot(comparaison_indices, aes(x = as.factor(Annee), y = Indice, group = Type, color = Type)) +
geom_line(size = 1.3) +
geom_point(size = 2) +
scale_color_manual(values = c("indice_perturbed" = "steelblue", "indice_model" = "darkorange"),
labels = c("indice_perturbed ", "Indice estimé (modèle)")) +
labs(
title = "Évolution des indices de prix des parcelles (2018–2024)",
subtitle = "Comparaison entre indice empirique et indice estimé par modèle hédonique",
x = "Année",
y = "Indice (base 100 en 2018)",
color = "Source"
) +
theme_minimal() +
theme(legend.position = "bottom")
#print(indice_perturbed$indice)
# Extraire les années et les indices
years <- as.numeric(as.character(indice_td$Annee))
indice_values <- indice_td$indice
# Tracer l'indice
plot(years, indice_values, type = "b", pch = 19, col = "blue",
xlab = "Année", ylab = "Indice des prix (base 2018 = 100)",
main = "Évolution de l'Indice des Prix Immobiliers (2018-2024)",
ylim = c(0, max(indice_values) * 1.1))  # Ajuster l'échelle
grid()  # Ajouter une grille
text(years, indice_values, labels = round(indice_values, 1), pos = 3, cex = 0.8)
# Récupérer l’importance
importance_matrix <- xgb.importance(model = xgb_model)
# Afficher dans un tableau kable
kable(importance_matrix, digits = 3, caption = "Importance des variables dans le modèle XGBoost")
indice_reel <- aggregate(Cout_m2 ~ Annee, data = sonatur, FUN = mean, na.rm = TRUE) #indice construit sans effets
indice_reel$indice <- (indice_reel$Cout_m2 / indice_reel$Cout_m2[indice_reel$Annee == "2018"]) * 100
# S'assurer que les noms de colonnes sont harmonisés
indice_reel_plot <- indice_reel %>%
select(Annee, indice_reel = indice)
indice_modele_plot <- indice_td %>%
select(Annee, indice_model = indice)
# Fusionner les deux indices
comparaison_indices <- full_join(indice_reel_plot, indice_modele_plot, by = "Annee") %>%
pivot_longer(cols = c("indice_reel", "indice_model"),
names_to = "Type", values_to = "Indice")
# Tracer les courbes
ggplot(comparaison_indices, aes(x = as.factor(Annee), y = Indice, group = Type, color = Type)) +
geom_line(size = 1.3) +
geom_point(size = 2) +
scale_color_manual(values = c("indice_reel" = "steelblue", "indice_model" = "darkorange"),
labels = c("Indice réel (moyenne annuelle)", "Indice estimé (modèle)")) +
labs(
title = "Évolution des indices de prix des parcelles (2018–2024)",
subtitle = "Comparaison entre indice empirique et indice estimé par modèle hédonique",
x = "Année",
y = "Indice (base 100 en 2018)",
color = "Source"
) +
theme_minimal() +
theme(legend.position = "bottom")
diagnostic_modele_gam_complet <- function(modele) {
# Résidus et prédictions
res <- residuals(modele)
yhat <- fitted(modele)
# 1. Normalité des résidus
test_norm <- shapiro.test(res)
norm_result <- c(
"Test de normalité des résidus (Shapiro-Wilk)",
paste0("W = ", round(test_norm$statistic, 3), ", p = ", format.pval(test_norm$p.value, digits = 3)),
ifelse(test_norm$p.value < 0.05, "Résidus non normalement distribués", "Résidus normalement distribués")
)
# 2. Hétéroscédasticité
bp_test <- tryCatch({
bptest(gam(formula(modele), data = modele$model, method = "ML"))
}, error = function(e) NULL)
hetero_result <- if (!is.null(bp_test)) {
c("Test de Breusch-Pagan (hétéroscédasticité)",
paste0("BP = ", round(bp_test$statistic, 3), ", p = ", format.pval(bp_test$p.value, digits = 3)),
ifelse(bp_test$p.value < 0.05, "Présence d'hétéroscédasticité", "Homoscédasticité"))
} else {
c("Test de Breusch-Pagan", "N/A", "Non applicable au modèle GAM directement")
}
# 3. Skewness
skew <- moments::skewness(res)
skew_result <- c(
"Asymétrie des résidus",
paste("Skewness =", round(skew, 2)),
ifelse(abs(skew) > 1, "Résidus fortement asymétriques", "Asymétrie modérée ou nulle")
)
# 4. Effets lissés
k_check <- summary(modele)$s.table
lin_result <- c(
"Test de linéarité (edf des splines)",
paste0("edf = ", paste(round(k_check[,"edf"], 2), collapse = ", ")),
ifelse(any(k_check[,"edf"] > 1.5), "Non-linéarité détectée", "Effets proches du linéaire")
)
linktest_result <- c("Test de spécification (Link test)", "N/A", "Non applicable au modèle GAM")
tableau <- rbind(norm_result, hetero_result, skew_result, lin_result, linktest_result)
colnames(tableau) <- c("Type de test", "Résultat", "Interprétation")
kable_table<- kable(as.data.frame(tableau), digits = 2,
caption = "Résumé des diagnostics du modèle GAM",
col.names = c("Type de test", "Résultat", "Interprétation")) %>%
kable_styling(latex_options = c("striped", "scale_down"), font_size = 12)
return(kable_table)
}
#Appel de la fonction de diagnostique
diagnostic_modele_gam_complet(modele_gam)
```{r, results='asis', message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
# Exemple fictif
df <- data.frame(
Annee = 2018:2024,
RMSE = c(18.2, 17.5, 16.9, 17.1, 15.6, 15.1, 14.9),
R2 = c(0.72, 0.75, 0.76, 0.77, 0.79, 0.80, 0.82),
Interpretation = c("Bonne", "Bonne", "Très bonne", "Très bonne", "Excellente", "Excellente", "Excellente")
)
# Générer le tableau personnalisé
kable(df, format = "latex", booktabs = TRUE, align = "c", caption = "Évaluation par année du modèle XGBoost") %>%
kable_styling(
latex_options = c("striped", "scale_down"),  # couleur alternée + ajuste largeur
font_size = 9,
position = "center"
) %>%
row_spec(0, bold = TRUE, color = "white", background = "#1c4587") %>%  # couleur en-tête
column_spec(2:3, color = "black") %>%  # couleur du texte pour colonnes numériques
add_header_above(c(" " = 1, "Performance" = 2, " " = 1))  # regroupement des colonnes
# Exemple fictif
df <- data.frame(
Annee = 2018:2024,
RMSE = c(18.2, 17.5, 16.9, 17.1, 15.6, 15.1, 14.9),
R2 = c(0.72, 0.75, 0.76, 0.77, 0.79, 0.80, 0.82),
Interpretation = c("Bonne", "Bonne", "Très bonne", "Très bonne", "Excellente", "Excellente", "Excellente")
)
# Générer le tableau personnalisé
kable(df, format = "latex", booktabs = TRUE, align = "c", caption = "Évaluation par année du modèle XGBoost") %>%
kable_styling(
latex_options = c("striped", "scale_down"),  # couleur alternée + ajuste largeur
font_size = 9,
position = "center"
) %>%
row_spec(0, bold = TRUE, color = "white", background = "#1c4587") %>%  # couleur en-tête
column_spec(2:3, color = "black") %>%  # couleur du texte pour colonnes numériques
add_header_above(c(" " = 1, "Performance" = 2, " " = 1))  # regroupement des colonnes
# Exemple fictif
df <- data.frame(
Annee = 2018:2024,
RMSE = c(18.2, 17.5, 16.9, 17.1, 15.6, 15.1, 14.9),
R2 = c(0.72, 0.75, 0.76, 0.77, 0.79, 0.80, 0.82),
Interpretation = c("Bonne", "Bonne", "Très bonne", "Très bonne", "Excellente", "Excellente", "Excellente")
)
# Générer le tableau personnalisé
kable(df, format = "latex", booktabs = TRUE, align = "c", caption = "Évaluation par année du modèle XGBoost") %>%
kable_styling(
latex_options = c("striped", "scale_down"),  # couleur alternée + ajuste largeur
font_size = 9,
position = "center"
) %>%
row_spec(0, bold = TRUE, color = "white", background = "yellow") %>%  # couleur en-tête
column_spec(2:3, color = "black") %>%  # couleur du texte pour colonnes numériques
add_header_above(c(" " = 1, "Performance" = 2, " " = 1))  # regroupement des colonnes
